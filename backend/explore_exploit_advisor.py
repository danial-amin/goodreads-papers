"""
Explore/Exploit Advisor

Analyzes user reading patterns to determine if they should:
- Go deep (exploit) in their current domain
- Explore adjacent/new domains
- Cross-pollinate between fields

This is a key differentiator for PaperReads.
"""

from sqlalchemy.orm import Session
from collections import Counter, defaultdict
from datetime import datetime, timedelta
import math
from typing import List, Dict, Optional, Tuple

from models import User, Paper, UserPaperInteraction, InteractionStatus


class ExploreExploitAdvisor:
    """Analyzes reading patterns and provides explore/exploit recommendations"""

    # Understanding level weights for depth calculation
    UNDERSTANDING_WEIGHTS = {
        InteractionStatus.WANT_TO_READ: 0.0,
        InteractionStatus.SKIMMED: 0.1,
        InteractionStatus.READING: 0.2,
        InteractionStatus.READ: 0.5,
        InteractionStatus.STUDIED: 0.8,
        InteractionStatus.IMPLEMENTED: 1.0,
        InteractionStatus.CITED: 1.0,
    }

    # Domain categories for grouping
    DOMAIN_GROUPS = {
        "Machine Learning": ["ml", "machine learning", "deep learning", "neural network"],
        "NLP": ["nlp", "natural language", "language model", "text", "transformer"],
        "Computer Vision": ["cv", "computer vision", "image", "visual", "object detection"],
        "Reinforcement Learning": ["rl", "reinforcement learning", "agent", "policy"],
        "Robotics": ["robotics", "robot", "manipulation", "navigation"],
        "Systems": ["systems", "distributed", "database", "storage", "networking"],
        "Security": ["security", "privacy", "cryptography", "adversarial"],
        "HCI": ["hci", "human computer", "interaction", "user interface", "ux"],
        "Theory": ["theory", "algorithm", "complexity", "optimization"],
        "Bioinformatics": ["bioinformatics", "genomics", "protein", "medical"],
    }

    @classmethod
    def get_domain_for_paper(cls, paper: Paper) -> List[str]:
        """Extract domains from a paper"""
        domains = []
        if paper.domains:
            domains = [d.strip().lower() for d in paper.domains.split(",")]

        # Also check keywords and smart_tags
        text_to_check = " ".join([
            paper.title.lower() if paper.title else "",
            (paper.keywords or "").lower(),
            (paper.smart_tags or "").lower(),
        ])

        # Map to canonical domain groups
        matched_domains = set()
        for canonical, keywords in cls.DOMAIN_GROUPS.items():
            for keyword in keywords:
                if keyword in text_to_check or keyword in " ".join(domains):
                    matched_domains.add(canonical)
                    break

        return list(matched_domains) if matched_domains else domains[:3] if domains else ["General"]

    @classmethod
    def calculate_domain_entropy(cls, domain_counts: Dict[str, int]) -> float:
        """
        Calculate Shannon entropy of domain distribution.
        Higher entropy = more diverse reading.
        """
        if not domain_counts:
            return 0.0

        total = sum(domain_counts.values())
        if total == 0:
            return 0.0

        entropy = 0.0
        for count in domain_counts.values():
            if count > 0:
                p = count / total
                entropy -= p * math.log2(p)

        # Normalize by max possible entropy
        max_entropy = math.log2(len(domain_counts)) if len(domain_counts) > 1 else 1
        return entropy / max_entropy if max_entropy > 0 else 0.0

    @classmethod
    def analyze_user(cls, user_id: int, db: Session) -> Dict:
        """
        Comprehensive analysis of user's reading patterns.
        Returns explore/exploit metrics and recommendations.
        """
        # Get all user interactions with papers
        interactions = (
            db.query(UserPaperInteraction)
            .filter(UserPaperInteraction.user_id == user_id)
            .all()
        )

        if not interactions:
            return cls._empty_analysis()

        # Get papers for these interactions
        paper_ids = [i.paper_id for i in interactions]
        papers = db.query(Paper).filter(Paper.id.in_(paper_ids)).all()
        paper_map = {p.id: p for p in papers}

        # Build domain statistics
        domain_counts = Counter()
        domain_depth = defaultdict(list)  # domain -> list of understanding scores
        recent_domains = Counter()  # Last 30 days

        thirty_days_ago = datetime.utcnow() - timedelta(days=30)

        for interaction in interactions:
            paper = paper_map.get(interaction.paper_id)
            if not paper:
                continue

            domains = cls.get_domain_for_paper(paper)
            weight = cls.UNDERSTANDING_WEIGHTS.get(interaction.status, 0.3)

            for domain in domains:
                domain_counts[domain] += 1
                domain_depth[domain].append(weight)

                # Track recent activity
                if interaction.created_at and interaction.created_at >= thirty_days_ago:
                    recent_domains[domain] += 1

        # Calculate metrics
        total_papers = len(interactions)
        num_domains = len(domain_counts)

        # Domain diversity (entropy-based)
        diversity_score = cls.calculate_domain_entropy(domain_counts)

        # Depth score (average understanding in primary domain)
        primary_domain = domain_counts.most_common(1)[0][0] if domain_counts else None
        depth_score = 0.0
        if primary_domain and domain_depth[primary_domain]:
            depth_score = sum(domain_depth[primary_domain]) / len(domain_depth[primary_domain])

        # Breadth score (number of domains with meaningful engagement)
        meaningful_domains = [d for d, scores in domain_depth.items() if sum(scores) / len(scores) >= 0.3]
        breadth_score = len(meaningful_domains)

        # Determine current mode
        mode, mode_confidence = cls._determine_mode(diversity_score, depth_score, breadth_score)

        # Build domain expertise breakdown
        domain_expertise = []
        for domain, count in domain_counts.most_common(10):
            scores = domain_depth.get(domain, [0])
            avg_depth = sum(scores) / len(scores) if scores else 0
            domain_expertise.append({
                "domain": domain,
                "papers": count,
                "depth": round(avg_depth, 2),
                "is_recent": domain in recent_domains,
            })

        # Get emerging interests (recent but low count)
        emerging = [d for d, c in recent_domains.items() if domain_counts[d] <= 3]

        # Generate recommendation
        recommendation, reason, suggested_domains = cls._generate_recommendation(
            mode=mode,
            diversity_score=diversity_score,
            depth_score=depth_score,
            domain_expertise=domain_expertise,
            primary_domain=primary_domain,
            total_papers=total_papers,
        )

        # Generate actionable suggestions
        suggested_actions = cls._generate_actions(
            recommendation=recommendation,
            domain_expertise=domain_expertise,
            primary_domain=primary_domain,
            emerging=emerging,
        )

        return {
            "current_mode": mode,
            "mode_confidence": round(mode_confidence, 2),
            "domain_diversity_score": round(diversity_score, 2),
            "depth_score": round(depth_score, 2),
            "breadth_score": breadth_score,
            "domain_expertise": domain_expertise,
            "primary_domain": primary_domain,
            "emerging_interests": emerging[:5],
            "recommendation": recommendation,
            "recommendation_reason": reason,
            "suggested_domains": suggested_domains,
            "suggested_actions": suggested_actions,
        }

    @classmethod
    def _determine_mode(
        cls, diversity: float, depth: float, breadth: int
    ) -> Tuple[str, float]:
        """Determine if user is exploring, exploiting, or balanced"""

        # High diversity + low depth = exploring
        if diversity > 0.7 and depth < 0.5:
            confidence = min(diversity, 1 - depth)
            return "exploring", confidence

        # Low diversity + high depth = exploiting
        if diversity < 0.4 and depth > 0.6:
            confidence = min(1 - diversity, depth)
            return "exploiting", confidence

        # Balanced
        balance_score = 1 - abs(diversity - 0.5) - abs(depth - 0.5)
        return "balanced", max(0.3, balance_score)

    @classmethod
    def _generate_recommendation(
        cls,
        mode: str,
        diversity_score: float,
        depth_score: float,
        domain_expertise: List[Dict],
        primary_domain: Optional[str],
        total_papers: int,
    ) -> Tuple[str, str, List[str]]:
        """Generate personalized recommendation"""

        # Not enough data
        if total_papers < 5:
            return (
                "build_foundation",
                "Read more papers to get personalized recommendations. Start with survey papers in your area of interest.",
                [],
            )

        # Heavy exploration, shallow understanding
        if mode == "exploring" and depth_score < 0.4:
            return (
                "go_deep",
                f"You've been exploring broadly but may benefit from deeper engagement. Consider studying papers in {primary_domain} more thoroughly.",
                [primary_domain] if primary_domain else [],
            )

        # Deep in one area, missing breadth
        if mode == "exploiting" and diversity_score < 0.3:
            # Find adjacent domains
            adjacent = cls._find_adjacent_domains(primary_domain)
            return (
                "explore_adjacent",
                f"Strong depth in {primary_domain}! Consider exploring adjacent fields to find cross-pollination opportunities.",
                adjacent[:3],
            )

        # Good depth, moderate diversity - suggest cross-pollination
        if depth_score > 0.6 and 0.3 <= diversity_score <= 0.6:
            secondary_domains = [d["domain"] for d in domain_expertise[1:4]]
            return (
                "cross_pollinate",
                f"You have expertise in {primary_domain}. Look for papers that combine it with {', '.join(secondary_domains[:2])}.",
                secondary_domains,
            )

        # Balanced - encourage maintaining
        return (
            "maintain_balance",
            "You're building T-shaped expertise - deep in some areas while staying broad. Keep it up!",
            [d["domain"] for d in domain_expertise[:3]],
        )

    @classmethod
    def _find_adjacent_domains(cls, domain: Optional[str]) -> List[str]:
        """Find domains adjacent to the given one"""
        adjacency = {
            "Machine Learning": ["NLP", "Computer Vision", "Reinforcement Learning", "Theory"],
            "NLP": ["Machine Learning", "HCI", "Knowledge Graphs"],
            "Computer Vision": ["Machine Learning", "Robotics", "Graphics"],
            "Reinforcement Learning": ["Machine Learning", "Robotics", "Game Theory"],
            "Robotics": ["Computer Vision", "Reinforcement Learning", "Control Systems"],
            "Systems": ["Security", "Databases", "Networking"],
            "Security": ["Systems", "Machine Learning", "Cryptography"],
            "HCI": ["NLP", "Computer Vision", "Design"],
            "Theory": ["Machine Learning", "Algorithms", "Optimization"],
            "Bioinformatics": ["Machine Learning", "Statistics", "Medical AI"],
        }
        return adjacency.get(domain, ["Machine Learning", "NLP", "Systems"])

    @classmethod
    def _generate_actions(
        cls,
        recommendation: str,
        domain_expertise: List[Dict],
        primary_domain: Optional[str],
        emerging: List[str],
    ) -> List[Dict]:
        """Generate specific actionable suggestions"""
        actions = []

        if recommendation == "go_deep":
            actions.append({
                "action": f"Find a seminal paper in {primary_domain} and study it thoroughly",
                "priority": "high",
                "type": "study",
            })
            actions.append({
                "action": "Try implementing a technique from a paper you've read",
                "priority": "medium",
                "type": "implement",
            })

        elif recommendation == "explore_adjacent":
            adjacent = cls._find_adjacent_domains(primary_domain)
            actions.append({
                "action": f"Read a survey paper in {adjacent[0] if adjacent else 'a new field'}",
                "priority": "high",
                "type": "explore",
            })
            actions.append({
                "action": f"Find papers combining {primary_domain} with {adjacent[1] if len(adjacent) > 1 else 'other fields'}",
                "priority": "medium",
                "type": "cross_pollinate",
            })

        elif recommendation == "cross_pollinate":
            if len(domain_expertise) >= 2:
                d1 = domain_expertise[0]["domain"]
                d2 = domain_expertise[1]["domain"]
                actions.append({
                    "action": f"Search for papers that combine {d1} and {d2}",
                    "priority": "high",
                    "type": "synthesis",
                })

        elif recommendation == "maintain_balance":
            actions.append({
                "action": "Continue your current reading pattern",
                "priority": "medium",
                "type": "maintain",
            })
            if emerging:
                actions.append({
                    "action": f"Explore your emerging interest in {emerging[0]}",
                    "priority": "low",
                    "type": "explore",
                })

        else:  # build_foundation
            actions.append({
                "action": "Start with survey papers to understand the landscape",
                "priority": "high",
                "type": "foundation",
            })
            actions.append({
                "action": "Set a goal to read 3 papers this week",
                "priority": "high",
                "type": "habit",
            })

        return actions

    @classmethod
    def _empty_analysis(cls) -> Dict:
        """Return empty analysis for users with no interactions"""
        return {
            "current_mode": "new_user",
            "mode_confidence": 0.0,
            "domain_diversity_score": 0.0,
            "depth_score": 0.0,
            "breadth_score": 0,
            "domain_expertise": [],
            "primary_domain": None,
            "emerging_interests": [],
            "recommendation": "build_foundation",
            "recommendation_reason": "Start your research journey! Add papers you're interested in to begin.",
            "suggested_domains": [],
            "suggested_actions": [
                {"action": "Add your first paper to start tracking", "priority": "high", "type": "start"},
                {"action": "Set your research interests in your profile", "priority": "medium", "type": "setup"},
            ],
        }
